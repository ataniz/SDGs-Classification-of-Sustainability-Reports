{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nlpaug\n",
    "!pip install transformers\n",
    "!pip install torch torchvision\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "\n",
    "from nlpaug.util.file.download import DownloadUtil\n",
    "# DownloadUtil.download_word2vec(dest_dir='.') # Download word2vec model\n",
    "# DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # Download GloVe model\n",
    "# DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # Download fasttext model\n",
    "!pip install simpletransformers>=0.61.10\n",
    "!pip install torch>=1.6.0 transformers>=4.11.3 sentencepiece\n",
    "!pip install sacremoses\n",
    "!pip install gensim>=4.1.2\n",
    "!pip install nltk>=3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source for augmenter https://nlpaug.readthedocs.io/en/latest/augmenter/word/synonym.html\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "augmented_text = aug.augment(text)\n",
    "\n",
    "df['synonym_aug'] = df['text'].apply(lambda x: aug.augment(x))\n",
    "\n",
    "#backtranslation \n",
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en',  device='cuda'\n",
    ")\n",
    "\n",
    "def backtranslate(x):\n",
    "  trans = back_translation_aug.augment(x)\n",
    "  print(trans)\n",
    "  return trans\n",
    "\n",
    "df['translate_aug'] = df['text'].apply(lambda x, i = 0: backtranslate(x))\n",
    "\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-large', action=\"substitute\", device='cuda')\n",
    "aug2 = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-large', action=\"insert\", device='cuda')\n",
    "augmented_text = aug.augment(text)\n",
    "\n",
    "def contextual_aug(text):\n",
    "  return aug.augment(aug2.augment(text))\n",
    "\n",
    "df['contextual_aug'] = df['text'].apply(lambda x: contextual_aug(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Define the SynonymAug augmenter with the WordNet thesaurus as the source\n",
    "syn_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "# Apply the SynonymAug augmenter to each text in the dataframe and save the augmented text in a new column\n",
    "df['synonym_aug'] = df['text'].apply(lambda x: syn_aug.augment(x))\n",
    "\n",
    "# Define the BackTranslationAug augmenter with the pre-trained translation models\n",
    "bt_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en', \n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Define a function to apply the BackTranslationAug augmenter to each text in the dataframe\n",
    "def backtranslate(x):\n",
    "    trans = bt_aug.augment(x)\n",
    "    # print(trans)\n",
    "    return trans\n",
    "\n",
    "# Apply the backtranslate function to each text in the dataframe and save the augmented text in a new column\n",
    "df['translate_aug'] = df['text'].apply(backtranslate)\n",
    "\n",
    "# Define the ContextualWordEmbsAug augmenter with the pre-trained RoBERTa model and the \"substitute\" action\n",
    "cont_aug_sub = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-large', \n",
    "    action=\"substitute\", \n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Define the ContextualWordEmbsAug augmenter with the pre-trained RoBERTa model and the \"insert\" action\n",
    "cont_aug_ins = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-large', \n",
    "    action=\"insert\", \n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Define a function to apply both ContextualWordEmbsAug augmenters to each text in the dataframe\n",
    "def contextual_aug(text):\n",
    "    return cont_aug_ins.augment(cont_aug_sub.augment(text))\n",
    "\n",
    "# Apply the contextual_aug function to each text in the dataframe and save the augmented text in a new column\n",
    "df['contextual_aug'] = df['text'].apply(contextual_aug)\n",
    "\n",
    "df['syn_and_contextual_aug'] = df['text'].apply(lambda x: contextual_aug(syn_augment(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
